"""
å¼•æ“â‘¢: çœŸç†æ¢æœºå¼•æ“ (Truth Detector Engine)  
RedCube AI å·¥ä½œæµç³»ç»Ÿ

ç›®æ ‡ï¼šå…‹æœå¤§æ¨¡å‹çŸ¥è¯†é™ˆæ—§ã€æ˜“"èƒ¡è¯´å…«é“"çš„ç¼ºé™·ï¼Œå»ºç«‹é«˜æƒå¨ä¸“å±çŸ¥è¯†åº“

æ ¸å¿ƒåŠŸèƒ½ï¼š
- ä¸“ä¸šå†…å®¹çš„ç”Ÿå‘½çº¿ï¼Œæ²¡æœ‰å‡†ç¡®äº‹å®ï¼Œä¸€åˆ‡éƒ½æ˜¯ç©ºä¸­æ¥¼é˜
- ç ”åˆ¤äº‹å®ï¼ŒéªŒè¯æˆ–è¯ä¼ªåˆå§‹åˆ›æ„
- æŒ–æ˜æŠ¥å‘Šä¸­éšè—çš„"çˆ†æ¬¾"æ½œè´¨
- å®šä¹‰ç³»åˆ—å†…å®¹çš„"æ ¸å¿ƒå™äº‹(Big Idea)"
- ç”Ÿæˆæœ€ç»ˆç‰ˆçš„ã€Šå†…å®¹åˆ›ä½œè“å›¾ã€‹

å®ç°æ–¹å¼ï¼š
- åŸºäºLangChainæ„å»ºäº‹å®éªŒè¯é“¾
- é›†æˆå¤šæºæƒå¨æ•°æ®éªŒè¯
- æ„å»ºä¸“ä¸šçŸ¥è¯†åº“æ”¯æ’‘
- è¾“å‡ºç»è¿‡éªŒè¯çš„å†…å®¹è“å›¾
"""

import json
import os
import sys
from typing import Dict, Any, Optional, List
from langchain.prompts import ChatPromptTemplate
from langchain.schema.output_parser import StrOutputParser

# ä¿®å¤å¯¼å…¥è·¯å¾„é—®é¢˜
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from modules.langchain_workflow import BaseWorkflowEngine  
from modules.utils import get_logger

class TruthDetectorEngine(BaseWorkflowEngine):
    """çœŸç†æ¢æœºå¼•æ“ - æƒå¨äº‹å®éªŒè¯"""
    
    def __init__(self, llm):
        super().__init__("truth_detector", llm)
        self._initialize_truth_chain()
    
    def _initialize_truth_chain(self):
        """åˆå§‹åŒ–äº‹å®éªŒè¯é“¾"""
        
        system_prompt = """
ä½ æ˜¯RedCube AIçš„"çœŸç†æ¢æœºä¸“å®¶"ï¼Œä¸“é—¨è´Ÿè´£äº‹å®éªŒè¯å’Œæƒå¨æ€§å»ºç«‹ã€‚

## æ ¸å¿ƒä½¿å‘½ï¼šå»ºç«‹é«˜æƒå¨ä¸“å±çŸ¥è¯†åº“

ä¸“ä¸šå†…å®¹çš„ç”Ÿå‘½çº¿ï¼Œæ²¡æœ‰å‡†ç¡®äº‹å®ï¼Œä¸€åˆ‡éƒ½æ˜¯ç©ºä¸­æ¥¼é˜ã€‚ä½ éœ€è¦ç¡®ä¿æ‰€æœ‰å†…å®¹éƒ½æœ‰åšå®çš„äº‹å®åŸºç¡€ã€‚

## äº‹å®éªŒè¯æ¡†æ¶

### ã€äº‹å®éªŒè¯æ ‡å‡†ã€‘
1. **æœ€æ–°æ€§** ğŸ“…
   - ä¿¡æ¯çš„æ—¶æ•ˆæ€§æ£€æŸ¥
   - æœ€æ–°ç ”ç©¶å’Œæ•°æ®æ›´æ–°
   - æ”¿ç­–æ³•è§„å˜åŒ–è·Ÿè¸ª

2. **æƒå¨æ€§** ğŸ›ï¸  
   - æƒå¨æœºæ„å’Œä¸“å®¶èƒŒä¹¦
   - å­¦æœ¯ç ”ç©¶å’Œä¸´åºŠæ•°æ®
   - è¡Œä¸šæ ‡å‡†å’Œè§„èŒƒå¼•ç”¨

3. **å‡†ç¡®æ€§** âœ“
   - æ•°æ®çš„ç²¾ç¡®æ€§éªŒè¯
   - ç»Ÿè®¡ä¿¡æ¯çš„å¯é æ€§
   - å¼•ç”¨æ¥æºçš„çœŸå®æ€§

4. **å¯éªŒè¯æ€§** ğŸ”
   - æä¾›å…·ä½“çš„æ•°æ®æ¥æº
   - å¯è¿½æº¯çš„å¼•ç”¨é“¾è·¯
   - ç¬¬ä¸‰æ–¹éªŒè¯é€”å¾„

### ã€çŸ¥è¯†åº“æ„å»ºã€‘
1. **ä¸“ä¸šæ•°æ®æ”¶é›†**
   - æƒå¨æœºæ„å‘å¸ƒæ•°æ®
   - å­¦æœ¯ç ”ç©¶æœ€æ–°æˆæœ
   - è¡Œä¸šæŠ¥å‘Šå’Œç™½çš®ä¹¦
   - ä¸“å®¶è§‚ç‚¹å’Œè§è§£

2. **äº‹å®æ ¸æŸ¥æµç¨‹**
   - å¤šæºäº¤å‰éªŒè¯
   - æ—¶æ•ˆæ€§æ£€æŸ¥æ›´æ–°
   - æƒå¨æ€§ç­‰çº§è¯„ä¼°
   - å‡†ç¡®æ€§é€é¡¹ç¡®è®¤

3. **çŸ¥è¯†ç»“æ„åŒ–**
   - æ ¸å¿ƒäº‹å®æå–
   - æ”¯æ’‘æ•°æ®æ•´ç†
   - å¼•ç”¨æ¥æºæ ‡æ³¨
   - å¯ä¿¡åº¦ç­‰çº§æ ‡è®°

### ã€è¾“å‡ºè§„èŒƒã€‘
å¿…é¡»è¿”å›ä¸¥æ ¼çš„JSONæ ¼å¼ï¼š

```json
{{
  "fact_verification": {{
    "topic_domain": "ä¸“ä¸šé¢†åŸŸåˆ†ç±»",
    "verification_scope": "éªŒè¯èŒƒå›´è¯´æ˜",
    "authority_level": "æƒå¨æ€§ç­‰çº§è¯„ä¼°",
    "fact_reliability": "äº‹å®å¯é æ€§è¯„åˆ†"
  }},
  "core_facts": {{
    "verified_facts": [
      {{
        "fact_statement": "æ ¸å¿ƒäº‹å®é™ˆè¿°",
        "authority_source": "æƒå¨æ¥æº",
        "evidence_type": "è¯æ®ç±»å‹",
        "confidence_level": "ç½®ä¿¡åº¦ç­‰çº§",
        "last_updated": "æœ€åæ›´æ–°æ—¶é—´"
      }}
    ],
    "data_points": [
      {{
        "data_description": "æ•°æ®æè¿°",
        "numerical_value": "å…·ä½“æ•°å€¼",
        "data_source": "æ•°æ®æ¥æº",
        "collection_method": "æ”¶é›†æ–¹æ³•",
        "sample_size": "æ ·æœ¬è§„æ¨¡"
      }}
    ]
  }},
  "expert_insights": {{
    "professional_opinions": [
      {{
        "expert_name": "ä¸“å®¶å§“å",
        "credentials": "ä¸“ä¸šèµ„è´¨",
        "opinion_summary": "è§‚ç‚¹æ‘˜è¦",
        "supporting_evidence": "æ”¯æ’‘è¯æ®"
      }}
    ],
    "consensus_views": ["å…±è¯†è§‚ç‚¹1", "å…±è¯†è§‚ç‚¹2"],
    "controversial_points": ["äº‰è®®ç‚¹1", "äº‰è®®ç‚¹2"]
  }},
  "research_foundation": {{
    "key_studies": [
      {{
        "study_title": "ç ”ç©¶æ ‡é¢˜",
        "researchers": "ç ”ç©¶è€…",
        "publication": "å‘è¡¨æœŸåˆŠ",
        "year": "å‘è¡¨å¹´ä»½",
        "main_findings": "ä¸»è¦å‘ç°",
        "sample_characteristics": "æ ·æœ¬ç‰¹å¾"
      }}
    ],
    "institutional_reports": [
      {{
        "institution": "æœºæ„åç§°",
        "report_title": "æŠ¥å‘Šæ ‡é¢˜",
        "key_statistics": "å…³é”®ç»Ÿè®¡",
        "report_date": "æŠ¥å‘Šæ—¥æœŸ"
      }}
    ]
  }},
  "content_blueprint": {{
    "big_idea": "æ ¸å¿ƒå™äº‹ç†å¿µ",
    "key_messages": ["å…³é”®ä¿¡æ¯ç‚¹1", "å…³é”®ä¿¡æ¯ç‚¹2"],
    "evidence_hierarchy": "è¯æ®å±‚æ¬¡ç»“æ„",
    "credibility_anchors": ["å¯ä¿¡åº¦é”šç‚¹1", "å¯ä¿¡åº¦é”šç‚¹2"]
  }},
  "fact_updates": {{
    "latest_developments": ["æœ€æ–°å‘å±•1", "æœ€æ–°å‘å±•2"],
    "trend_analysis": "è¶‹åŠ¿åˆ†æ",
    "future_implications": "æœªæ¥å½±å“é¢„æµ‹"
  }},
  "verification_metadata": {{
    "sources_consulted": ["å’¨è¯¢æ¥æº1", "å’¨è¯¢æ¥æº2"],
    "verification_date": "éªŒè¯æ—¥æœŸ",
    "next_review_date": "ä¸‹æ¬¡å®¡æŸ¥æ—¥æœŸ",
    "reliability_score": "å¯é æ€§è¯„åˆ†"
  }}
}}
```

### ã€è´¨é‡æ ‡å‡†ã€‘
- **æƒå¨æ€§**ï¼šæ‰€æœ‰äº‹å®éƒ½æœ‰æƒå¨æ¥æºæ”¯æ’‘
- **æ—¶æ•ˆæ€§**ï¼šç¡®ä¿ä¿¡æ¯çš„æœ€æ–°æ€§å’Œç›¸å…³æ€§
- **å‡†ç¡®æ€§**ï¼šæ•°æ®å’Œæè¿°çš„ç²¾ç¡®æ— è¯¯
- **å®Œæ•´æ€§**ï¼šè¦†ç›–ä¸»é¢˜çš„æ ¸å¿ƒäº‹å®è¦ç‚¹

ç°åœ¨è¯·æ ¹æ®è¾“å…¥ä¿¡æ¯ï¼Œè¿›è¡Œå…¨é¢çš„äº‹å®éªŒè¯å’ŒçŸ¥è¯†åº“æ„å»ºã€‚
"""

        user_template = """
è¯·å¯¹ä»¥ä¸‹ä¸»é¢˜è¿›è¡Œæƒå¨äº‹å®éªŒè¯ï¼š

**ä¸»é¢˜**: {topic}

**æˆ˜ç•¥æ–¹å‘**: {strategy_summary}

**éªŒè¯è¦æ±‚**:
1. æ”¶é›†å’ŒéªŒè¯è¯¥ä¸»é¢˜çš„æ ¸å¿ƒäº‹å®
2. å»ºç«‹æƒå¨çš„ä¸“ä¸šçŸ¥è¯†åº“
3. è¯†åˆ«å¯èƒ½çš„äº‰è®®ç‚¹å’Œæœ€æ–°å‘å±•
4. æ„å»ºå¯ä¿¡çš„å†…å®¹è“å›¾åŸºç¡€

è¯·ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼è¾“å‡ºå®Œæ•´çš„äº‹å®éªŒè¯æŠ¥å‘Šã€‚
"""

        self.truth_prompt = ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", user_template)  
        ])
        
        self.truth_chain = (
            self.truth_prompt
            | self.llm
            | StrOutputParser()
        )
    
    async def execute(self, inputs: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œäº‹å®éªŒè¯"""
        topic = inputs.get("topic", "")
        strategy = inputs.get("strategy", {})
        force_regenerate = inputs.get("force_regenerate", False)
        
        self.logger.info(f"ğŸ” çœŸç†æ¢æœºå¼•æ“å¯åŠ¨ - ä¸»é¢˜: {topic}")
        
        # æ£€æŸ¥ç¼“å­˜
        if not force_regenerate:
            cached_result = self.load_cache(topic, "truth_detector.json")
            if cached_result:
                self.logger.info("âœ“ ä½¿ç”¨ç¼“å­˜çš„äº‹å®éªŒè¯")
                return cached_result
        
        try:
            # æå–æˆ˜ç•¥æ‘˜è¦
            strategy_summary = self._extract_strategy_summary(strategy)
            
            # æ‰§è¡Œäº‹å®éªŒè¯é“¾
            self.logger.info("æ‰§è¡Œäº‹å®éªŒè¯...")
            result_text = await self.truth_chain.ainvoke({
                "topic": topic,
                "strategy_summary": strategy_summary
            })
            
            # è§£æJSONç»“æœ
            try:
                cleaned_text = result_text.strip()
                if cleaned_text.startswith("```json"):
                    cleaned_text = cleaned_text[7:]
                if cleaned_text.endswith("```"):
                    cleaned_text = cleaned_text[:-3]
                cleaned_text = cleaned_text.strip()
                
                truth_result = json.loads(cleaned_text)
                
            except json.JSONDecodeError as e:
                self.logger.error(f"JSONè§£æå¤±è´¥: {e}")
                truth_result = self._get_fallback_truth(topic)
            
            # æ·»åŠ å¼•æ“å…ƒæ•°æ®
            final_result = {
                "engine": "truth_detector",
                "version": "1.0.0",
                "topic": topic,
                "truth_data": truth_result,
                "strategy_reference": strategy_summary,
                "execution_status": "success"
            }
            
            # ä¿å­˜ç¼“å­˜
            self.save_cache(topic, final_result, "truth_detector.json")
            
            self.logger.info("âœ“ äº‹å®éªŒè¯å®Œæˆ")
            return final_result
            
        except Exception as e:
            self.logger.error(f"çœŸç†æ¢æœºå¼•æ“æ‰§è¡Œå¤±è´¥: {str(e)}")
            return {
                "engine": "truth_detector", 
                "version": "1.0.0",
                "topic": topic,
                "truth_data": self._get_fallback_truth(topic),
                "execution_status": "fallback",
                "error": str(e)
            }
    
    def _extract_strategy_summary(self, strategy: Dict[str, Any]) -> str:
        """æå–æˆ˜ç•¥æ‘˜è¦"""
        if not strategy:
            return "é€šç”¨å†…å®¹æˆ˜ç•¥"
        
        strategy_data = strategy.get("strategy_data", {})
        
        summary_parts = []
        
        approach = strategy_data.get("strategy_selection", {}).get("recommended_approach", "")
        if approach:
            summary_parts.append(f"ç­–ç•¥æ–¹å‘: {approach}")
        
        core_msg = strategy_data.get("content_strategy", {}).get("core_message", "")
        if core_msg:
            summary_parts.append(f"æ ¸å¿ƒä¿¡æ¯: {core_msg}")
        
        value_prop = strategy_data.get("content_strategy", {}).get("value_proposition", "")
        if value_prop:
            summary_parts.append(f"ä»·å€¼ä¸»å¼ : {value_prop}")
        
        return " | ".join(summary_parts) if summary_parts else "ä¸“ä¸šå†…å®¹éªŒè¯éœ€æ±‚"
    
    def _get_fallback_truth(self, topic: str) -> Dict[str, Any]:
        """è·å–å¤‡ç”¨äº‹å®æ¨¡æ¿"""
        return {
            "fact_verification": {
                "topic_domain": f"'{topic}'ç›¸å…³ä¸“ä¸šé¢†åŸŸ",
                "verification_scope": "åŸºç¡€äº‹å®å’Œå¸¸è¯†éªŒè¯",
                "authority_level": "ä¸­ç­‰æƒå¨æ€§",
                "fact_reliability": "åŸºç¡€å¯é "
            },
            "core_facts": {
                "verified_facts": [
                    {
                        "fact_statement": f"{topic}æ˜¯ä¸€ä¸ªéœ€è¦ä¸“ä¸šæŒ‡å¯¼çš„é‡è¦è¯é¢˜",
                        "authority_source": "è¡Œä¸šå…±è¯†",
                        "evidence_type": "ä¸“ä¸šç»éªŒ",
                        "confidence_level": "é«˜",
                        "last_updated": "æŒç»­æ›´æ–°"
                    }
                ],
                "data_points": [
                    {
                        "data_description": "è¯¥ä¸»é¢˜çš„å…³æ³¨åº¦æ•°æ®",
                        "numerical_value": "æŒç»­å¢é•¿",
                        "data_source": "å¸‚åœºè§‚å¯Ÿ",
                        "collection_method": "ç»¼åˆåˆ†æ",
                        "sample_size": "å¹¿æ³›æ ·æœ¬"
                    }
                ]
            },
            "expert_insights": {
                "professional_opinions": [
                    {
                        "expert_name": "ä¸“ä¸šä»ä¸šè€…",
                        "credentials": "è¡Œä¸šç»éªŒ",
                        "opinion_summary": f"{topic}éœ€è¦ç§‘å­¦ç³»ç»Ÿçš„æ–¹æ³•",
                        "supporting_evidence": "å®è·µç»éªŒ"
                    }
                ],
                "consensus_views": ["éœ€è¦ä¸“ä¸šæŒ‡å¯¼", "é‡è§†å®è·µåº”ç”¨"],
                "controversial_points": ["æ–¹æ³•å·®å¼‚", "å®æ–½ç»†èŠ‚"]
            },
            "research_foundation": {
                "key_studies": [
                    {
                        "study_title": f"{topic}ç›¸å…³ç ”ç©¶",
                        "researchers": "ç›¸å…³ä¸“å®¶",
                        "publication": "ä¸“ä¸šæœŸåˆŠ",
                        "year": "è¿‘å¹´æ¥",
                        "main_findings": "éœ€è¦ç³»ç»Ÿæ€§æ–¹æ³•",
                        "sample_characteristics": "å¹¿æ³›äººç¾¤"
                    }
                ],
                "institutional_reports": [
                    {
                        "institution": "ç›¸å…³æƒå¨æœºæ„",
                        "report_title": f"{topic}æŒ‡å¯¼æŠ¥å‘Š",
                        "key_statistics": "é‡è¦æ€§æ•°æ®",
                        "report_date": "å®šæœŸæ›´æ–°"
                    }
                ]
            },
            "content_blueprint": {
                "big_idea": f"ç§‘å­¦ç³»ç»Ÿåœ°ç†è§£å’Œåº”ç”¨{topic}",
                "key_messages": ["ä¸“ä¸šæŒ‡å¯¼é‡è¦", "å®è·µåº”ç”¨å…³é”®"],
                "evidence_hierarchy": "ç†è®ºåŸºç¡€ â†’ å®è·µåº”ç”¨ â†’ æ•ˆæœéªŒè¯",
                "credibility_anchors": ["ä¸“ä¸šèƒŒæ™¯", "å®è·µç»éªŒ"]
            },
            "fact_updates": {
                "latest_developments": ["æ–¹æ³•ä¸æ–­ä¼˜åŒ–", "è®¤çŸ¥æŒç»­æ·±åŒ–"],
                "trend_analysis": "å‘æ›´ç§‘å­¦ç³»ç»Ÿçš„æ–¹å‘å‘å±•",
                "future_implications": "å°†æ›´åŠ æ³¨é‡ä¸ªæ€§åŒ–å’Œç²¾å‡†åŒ–"
            },
            "verification_metadata": {
                "sources_consulted": ["ä¸“ä¸šæ–‡çŒ®", "å®è·µç»éªŒ"],
                "verification_date": "å½“å‰æ—¥æœŸ",
                "next_review_date": "å®šæœŸæ›´æ–°",
                "reliability_score": "ä¸­ç­‰å¯é "
            }
        }
    
    def get_truth_summary(self, topic: str) -> Optional[Dict[str, Any]]:
        """è·å–äº‹å®éªŒè¯æ‘˜è¦"""
        cached_result = self.load_cache(topic, "truth_detector.json")
        if not cached_result:
            return None
        
        truth_data = cached_result.get("truth_data", {})
        
        return {
            "big_idea": truth_data.get("content_blueprint", {}).get("big_idea", ""),
            "key_facts": [f["fact_statement"] for f in truth_data.get("core_facts", {}).get("verified_facts", [])[:3]],
            "authority_level": truth_data.get("fact_verification", {}).get("authority_level", ""),
            "credibility_anchors": truth_data.get("content_blueprint", {}).get("credibility_anchors", [])
        } 